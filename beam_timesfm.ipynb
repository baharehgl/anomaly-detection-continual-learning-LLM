{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e56262-427f-4bfb-91cd-993a0735f727",
   "metadata": {},
   "source": [
    "Start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8c0e8a-f25e-432a-9be4-52620e63673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timesfm[torch] in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: absl-py>=1.4.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from timesfm[torch]) (2.1.0)\n",
      "Requirement already satisfied: einshape>=1.0.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from timesfm[torch]) (1.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.23.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from huggingface_hub[cli]>=0.23.0->timesfm[torch]) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from timesfm[torch]) (2.0.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from timesfm[torch]) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from timesfm[torch]) (1.7.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from torch[cuda]>=2.0.0; python_version == \"3.11\" and extra == \"torch\"->timesfm[torch]) (2.9.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from timesfm[torch]) (0.20.0)\n",
      "Requirement already satisfied: utilsforecast>=0.1.10 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from timesfm[torch]) (0.2.14)\n",
      "Requirement already satisfied: wandb>=0.17.5 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from timesfm[torch]) (0.22.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.27.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (6.0.2)\n",
      "Requirement already satisfied: shellingham in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (4.67.0)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=2.0.0->timesfm[torch]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=2.0.0->timesfm[torch]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=2.0.0->timesfm[torch]) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=1.2.2->timesfm[torch]) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from scikit-learn>=1.2.2->timesfm[torch]) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from scikit-learn>=1.2.2->timesfm[torch]) (3.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from torch>=2.0.0->torch[cuda]>=2.0.0; python_version == \"3.11\" and extra == \"torch\"->timesfm[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from torch>=2.0.0->torch[cuda]>=2.0.0; python_version == \"3.11\" and extra == \"torch\"->timesfm[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->torch[cuda]>=2.0.0; python_version == \"3.11\" and extra == \"torch\"->timesfm[torch]) (3.1.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from typer>=0.12.3->timesfm[torch]) (8.3.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from typer>=0.12.3->timesfm[torch]) (13.9.4)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from wandb>=0.17.5->timesfm[torch]) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from wandb>=0.17.5->timesfm[torch]) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from wandb>=0.17.5->timesfm[torch]) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from wandb>=0.17.5->timesfm[torch]) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from wandb>=0.17.5->timesfm[torch]) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from wandb>=0.17.5->timesfm[torch]) (2.43.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.0.0->typer>=0.12.3->timesfm[torch]) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.5->timesfm[torch]) (4.0.12)\n",
      "Requirement already satisfied: anyio in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3->wandb>=0.17.5->timesfm[torch]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3->wandb>=0.17.5->timesfm[torch]) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->timesfm[torch]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.0.0->wandb>=0.17.5->timesfm[torch]) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.0.0->wandb>=0.17.5->timesfm[torch]) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer>=0.12.3->timesfm[torch]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer>=0.12.3->timesfm[torch]) (2.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->torch[cuda]>=2.0.0; python_version == \"3.11\" and extra == \"torch\"->timesfm[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=2.0.0->torch[cuda]>=2.0.0; python_version == \"3.11\" and extra == \"torch\"->timesfm[torch]) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\robotics\\miniconda3\\envs\\tfm311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.5->timesfm[torch]) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->timesfm[torch]) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: huggingface-hub 1.1.2 does not provide the extra 'cli'\n",
      "WARNING: torch 2.9.0 does not provide the extra 'cuda'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: \"'apache_beam[interactive,gcp,test]\": Expected package name at the start of dependency specifier\n",
      "    'apache_beam[interactive,gcp,test]\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Using cached google_api_python_client-2.187.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\robotics\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Using cached google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Using cached google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Using cached google_api_python_client-2.187.0-py3-none-any.whl (14.6 MB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Using cached google_auth_httplib2-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Using cached httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 4.5/4.7 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 21.9 MB/s eta 0:00:00\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pyasn1, proto-plus, httplib2, grpcio, googleapis-common-protos, cachetools, rsa, pyasn1-modules, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.70.0\n",
      "    Uninstalling grpcio-1.70.0:\n",
      "      Successfully uninstalled grpcio-1.70.0\n",
      "Successfully installed cachetools-6.2.1 google-ai-generativelanguage-0.6.15 google-api-core-2.28.1 google-api-python-client-2.187.0 google-auth-2.43.0 google-auth-httplib2-0.2.1 google-generativeai-0.8.5 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 uritemplate-4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install timesfm[torch]\n",
    "!pip install 'apache_beam[interactive,gcp,test] == 2.67.0'\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615dce56-f95e-4f20-ba69-36c57ff6051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import GCSFileSystem; loading of this filesystem will be skipped. Error details: cannot import name 'storage' from 'google.cloud' (unknown location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]\n",
      "Beam: 2.67.0\n"
     ]
    }
   ],
   "source": [
    "import sys, apache_beam as beam\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Beam:\", beam.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932c14a3-5ced-46e6-8fb0-66bab95e2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, bisect\n",
    "import apache_beam as beam\n",
    "from apache_beam.coders import BooleanCoder, PickleCoder, TimestampCoder\n",
    "from apache_beam.transforms.timeutil import TimeDomain\n",
    "from apache_beam.transforms.userstate import ReadModifyWriteStateSpec, TimerSpec, on_timer\n",
    "from apache_beam.utils.timestamp import MAX_TIMESTAMP, Timestamp\n",
    "\n",
    "# Try to import OrderedListStateSpec; fall back if unavailable.\n",
    "try:\n",
    "    from apache_beam.transforms.userstate import OrderedListStateSpec  \n",
    "    _HAS_ORDERED_LIST = True\n",
    "except Exception:\n",
    "    _HAS_ORDERED_LIST = False\n",
    "\n",
    "_LOGGER = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "_LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "class OrderedSlidingWindowFn(beam.DoFn):\n",
    "  # Use OrderedListState when available; otherwise store a sorted Python list via ReadModifyWriteState\n",
    "  if _HAS_ORDERED_LIST:\n",
    "    ORDERED_BUFFER_STATE = OrderedListStateSpec('ordered_buffer', PickleCoder())\n",
    "  else:\n",
    "    ORDERED_BUFFER_STATE = ReadModifyWriteStateSpec('ordered_buffer', PickleCoder())\n",
    "\n",
    "  WINDOW_TIMER = TimerSpec('window_timer', TimeDomain.WATERMARK)\n",
    "  TIMER_STATE = ReadModifyWriteStateSpec('timer_state', BooleanCoder())\n",
    "  EARLIEST_TS_STATE = ReadModifyWriteStateSpec('earliest_ts', TimestampCoder())\n",
    "\n",
    "  def __init__(self, window_size, slide_interval):\n",
    "    # window_size, slide_interval are in seconds (ints/floats)\n",
    "    self.window_size = window_size\n",
    "    self.slide_interval = slide_interval\n",
    "\n",
    "  def start_bundle(self):\n",
    "    _LOGGER.debug(\"start bundle\")\n",
    "\n",
    "  def finish_bundle(self):\n",
    "    _LOGGER.debug(\"finish bundle\")\n",
    "\n",
    "  def _insert_sorted(self, buf, ts, val):\n",
    "    \n",
    "    # sort by microseconds to avoid relying on Timestamp rich-compare on all platforms\n",
    "    keys = [int(t.micros) for t, _ in buf]\n",
    "    pos = bisect.bisect_right(keys, int(ts.micros))\n",
    "    buf.insert(pos, (ts, val))\n",
    "    return buf\n",
    "\n",
    "  def process(\n",
    "      self,\n",
    "      element,\n",
    "      timestamp=beam.DoFn.TimestampParam,\n",
    "      ordered_buffer=beam.DoFn.StateParam(ORDERED_BUFFER_STATE),\n",
    "      window_timer=beam.DoFn.TimerParam(WINDOW_TIMER),\n",
    "      timer_state=beam.DoFn.StateParam(TIMER_STATE),\n",
    "      earliest_ts_state=beam.DoFn.StateParam(EARLIEST_TS_STATE)):\n",
    "\n",
    "    _, value = element\n",
    "\n",
    "    if _HAS_ORDERED_LIST:\n",
    "      ordered_buffer.add((timestamp, value))\n",
    "    else:\n",
    "      buf = ordered_buffer.read() or []\n",
    "      buf = self._insert_sorted(buf, timestamp, value)\n",
    "      ordered_buffer.write(buf)\n",
    "\n",
    "    _LOGGER.debug(\"receive %s at %s\", element, timestamp)\n",
    "    timer_started = timer_state.read()\n",
    "\n",
    "    earliest = earliest_ts_state.read()\n",
    "    if not earliest or earliest > timestamp:\n",
    "      earliest_ts_state.write(timestamp)\n",
    "\n",
    "    if not timer_started:\n",
    "      earliest_ts_state.write(timestamp)\n",
    "      first_slide_start = int(timestamp.micros / 1e6 // self.slide_interval) * self.slide_interval\n",
    "      first_slide_start_ts = Timestamp.of(first_slide_start)\n",
    "      first_window_end_ts = first_slide_start_ts + self.window_size\n",
    "      _LOGGER.debug(\"set timer to %s\", first_window_end_ts)\n",
    "      window_timer.set(first_window_end_ts)\n",
    "      timer_state.write(True)\n",
    "\n",
    "    return []\n",
    "\n",
    "  @on_timer(WINDOW_TIMER)\n",
    "  def on_timer(\n",
    "      self,\n",
    "      key=beam.DoFn.KeyParam,\n",
    "      fire_ts=beam.DoFn.TimestampParam,\n",
    "      ordered_buffer=beam.DoFn.StateParam(ORDERED_BUFFER_STATE),\n",
    "      window_timer=beam.DoFn.TimerParam(WINDOW_TIMER),\n",
    "      timer_state=beam.DoFn.StateParam(TIMER_STATE),\n",
    "      earliest_ts_state=beam.DoFn.StateParam(EARLIEST_TS_STATE)):\n",
    "\n",
    "    _LOGGER.debug(\"timer fire at %s\", fire_ts)\n",
    "    window_end_ts = fire_ts\n",
    "    window_start_ts = window_end_ts - self.window_size\n",
    "\n",
    "    if _HAS_ORDERED_LIST:\n",
    "      window_values = list(ordered_buffer.read_range(window_start_ts, window_end_ts))\n",
    "    else:\n",
    "      buf = ordered_buffer.read() or []\n",
    "      # take items in [window_start_ts, window_end_ts)\n",
    "      window_values = [(ts, val) for (ts, val) in buf if window_start_ts <= ts < window_end_ts]\n",
    "\n",
    "    _LOGGER.debug(\"window start: %s, window end: %s\", window_start_ts, window_end_ts)\n",
    "    _LOGGER.debug(\"windowed data in buffer %s\", str(window_values))\n",
    "    if window_values:\n",
    "      yield (key, (window_start_ts, window_end_ts, window_values))\n",
    "\n",
    "    next_window_end_ts = fire_ts + self.slide_interval\n",
    "    next_window_start_ts = window_start_ts + self.slide_interval\n",
    "\n",
    "    if _HAS_ORDERED_LIST:\n",
    "      earliest_ts = earliest_ts_state.read()\n",
    "      ordered_buffer.clear_range(earliest_ts, next_window_start_ts)\n",
    "      remaining_data = list(ordered_buffer.read_range(next_window_start_ts, MAX_TIMESTAMP))\n",
    "      if not remaining_data:\n",
    "        timer_state.clear()\n",
    "        earliest_ts_state.write(next_window_start_ts)\n",
    "        return\n",
    "      _LOGGER.debug(\"set timer to %s\", next_window_end_ts)\n",
    "      window_timer.set(next_window_end_ts)\n",
    "    else:\n",
    "      # prune older-than next_window_start_ts and write back\n",
    "      buf = ordered_buffer.read() or []\n",
    "      buf = [(ts, val) for (ts, val) in buf if ts >= next_window_start_ts]\n",
    "      ordered_buffer.write(buf)\n",
    "      if not buf:\n",
    "        timer_state.clear()\n",
    "        earliest_ts_state.write(next_window_start_ts)\n",
    "        return\n",
    "      _LOGGER.debug(\"set timer to %s\", next_window_end_ts)\n",
    "      window_timer.set(next_window_end_ts)\n",
    "\n",
    "class FillGapsFn(beam.DoFn):\n",
    "  def __init__(self, expected_interval: float):\n",
    "    self.expected_interval = expected_interval  # seconds\n",
    "\n",
    "  def process(self, element):\n",
    "    key, (window_start_ts, window_end_ts, window_elements) = element\n",
    "    received_data = {round(float(ts.micros / 1e6), 5): val for ts, val in window_elements}\n",
    "    start_sec = float(window_start_ts.micros / 1e6)\n",
    "    end_sec = float(window_end_ts.micros / 1e6)\n",
    "\n",
    "    filled_values = []\n",
    "    current_ts_sec = start_sec\n",
    "    while current_ts_sec < end_sec:\n",
    "      lookup_ts = round(current_ts_sec, 5)\n",
    "      filled_values.append(float(received_data[lookup_ts]) if lookup_ts in received_data else 'NaN')\n",
    "      current_ts_sec += self.expected_interval\n",
    "\n",
    "    yield (key, (window_start_ts, window_end_ts, filled_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f852987-ff2e-4dcc-98e2-7a0534eeabce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c6b274-538c-40f2-aae0-9ef59741892d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timesfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mapache_beam\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbeam\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapache_beam\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelHandler\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimesfm\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'timesfm'"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.ml.inference.base import ModelHandler\n",
    "import timesfm\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from apache_beam.io.gcp.gcsio import GcsIO\n",
    "from apache_beam.utils.timestamp import Timestamp\n",
    "\n",
    "class LatestModelCheckpointLoader(beam.PTransform):\n",
    "    \"\"\"A PTransform that finds the latest model checkpoint in a GCS path.\"\"\"\n",
    "    def __init__(self, gcs_bucket, gcs_prefix):\n",
    "        self.gcs_bucket = gcs_bucket\n",
    "        self.gcs_prefix = gcs_prefix\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "        return pcoll | \"FindLatestModel\" >> beam.Map(self._find_latest_model_path)\n",
    "\n",
    "    def _find_latest_model_path(self, _):\n",
    "        try:\n",
    "            storage_client = storage.Client()\n",
    "            blobs = storage_client.list_blobs(self.gcs_bucket, prefix=self.gcs_prefix)\n",
    "            # Filter for model files and find the most recent one\n",
    "            model_blobs = [b for b in blobs if b.name.endswith(\".pth\")]\n",
    "            latest_blob = max(model_blobs, key=lambda b: b.time_created, default=None)\n",
    "\n",
    "            if latest_blob:\n",
    "                path = f\"gs://{self.gcs_bucket}/{latest_blob.name}\"\n",
    "                logging.info(f\"Found latest finetuned model at: {path}\")\n",
    "                return path\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error finding latest model in GCS: {e}\")\n",
    "\n",
    "        # Return a path to the base model if no finetuned one exists or an error occurs\n",
    "        base_model = \"google/timesfm-1.0-200m-pytorch\"\n",
    "        logging.info(f\"No finetuned model found. Using base model: {base_model}\")\n",
    "        return base_model\n",
    "\n",
    "class DynamicTimesFmModelHandler(ModelHandler[np.ndarray, np.ndarray, timesfm.TimesFm]):\n",
    "    \"\"\"\n",
    "    A model handler that loads a TimesFM model from a dynamic path (GCS or Hugging Face).\n",
    "    The model path is provided as a side input to RunInference.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_uri: str, hparams):\n",
    "        self._hparams = hparams\n",
    "        self._model = None\n",
    "        self._model_uri = model_uri\n",
    "        self._context_len = hparams.context_len\n",
    "        self._horizon_len = hparams.horizon_len\n",
    "\n",
    "    def load_model(self) -> timesfm.TimesFm:\n",
    "        \"\"\"Loads a model from the handler's current model_uri.\"\"\"\n",
    "        logging.info(f\"Loading TimesFM model from path: {self._model_uri}...\")\n",
    "\n",
    "        checkpoint_config = {}\n",
    "        if self._model_uri.startswith(\"gs://\"):\n",
    "            try:\n",
    "                gcs = GcsIO()\n",
    "                file_name = os.path.basename(self._model_uri)\n",
    "                local_path = f\"/tmp/{file_name}\"\n",
    "                with gcs.open(self._model_uri, 'rb') as f_in, open(local_path, 'wb') as f_out:\n",
    "                    f_out.write(f_in.read())\n",
    "                checkpoint_config['path'] = local_path\n",
    "                logging.info(f\"Downloaded model from GCS to {local_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to download model from GCS: {e}. Check path and permissions.\")\n",
    "                raise e # Re-raise the exception to fail fast if the model can't be loaded.\n",
    "        else:\n",
    "            checkpoint_config['huggingface_repo_id'] = self._model_uri\n",
    "\n",
    "        self._model = timesfm.TimesFm(\n",
    "            hparams=self._hparams,\n",
    "            checkpoint=timesfm.TimesFmCheckpoint(**checkpoint_config)\n",
    "        )\n",
    "        logging.info(\"TimesFM model loaded successfully.\")\n",
    "        return self._model\n",
    "\n",
    "    def update_model_path(self, model_path: str):\n",
    "        \"\"\"\n",
    "        This method is called by RunInference when a new model metadata is available\n",
    "        from the side input. It updates the model URI that `load_model` will use.\n",
    "        \"\"\"\n",
    "        if not model_path:\n",
    "            logging.info(\"Received an empty model path update. No action taken.\")\n",
    "            return\n",
    "        logging.info(f\"Received model update. New model URI: {model_path}\")\n",
    "        self._model_uri = model_path\n",
    "        self._model = self.load_model()\n",
    "        logging.info(\"Model has been updated in the handler.\")\n",
    "\n",
    "    def run_inference(self, batch, model, inference_args=None):\n",
    "        \"\"\"\n",
    "            Runs inference on a batch of data.\n",
    "\n",
    "            Note: While this is a standard method for ModelHandler, we will call the\n",
    "            model's `forecast` method directly in our DoFn for clarity.\n",
    "            \"\"\"\n",
    "        # print(\"Running inference on batch:\", batch)\n",
    "        # logging.info(f\"Running inference on batch:\", batch)\n",
    "\n",
    "        anomalies_found = []\n",
    "\n",
    "        key, (window_start_ts, _, values_array) = batch[0]\n",
    "\n",
    "        # A window must have enough data for both context and horizon.\n",
    "        # if len(values_array) < self.context_len + self.horizon_len:\n",
    "        #     return\n",
    "\n",
    "        current_context = np.array(values_array[:self._context_len])\n",
    "        actual_horizon_values = np.array(\n",
    "            values_array[self._context_len:self._context_len + self._horizon_len])\n",
    "\n",
    "        print(\"Current context shape:\", current_context.shape)\n",
    "        print(\"Actual horizon values shape:\", actual_horizon_values.shape)\n",
    "        point_forecast, experimental_quantile_forecast = model.forecast(\n",
    "            [current_context],\n",
    "            freq=[0],\n",
    "        )\n",
    "\n",
    "        current_predicted_horizon_values = point_forecast[\n",
    "            0, :, 0] if point_forecast.ndim == 3 else point_forecast[0]\n",
    "\n",
    "        current_q20_values = experimental_quantile_forecast[0, :, 2]\n",
    "        current_q30_values = experimental_quantile_forecast[0, :, 3]\n",
    "        current_q70_values = experimental_quantile_forecast[0, :, 7]\n",
    "        current_q80_values = experimental_quantile_forecast[0, :, 8]\n",
    "\n",
    "        for j in range(len(actual_horizon_values)):\n",
    "            current_actual = actual_horizon_values[j]\n",
    "\n",
    "            point_Q1 = np.nanmean([current_q20_values[j], current_q30_values[j]])\n",
    "            point_Q3 = np.nanmean([current_q70_values[j], current_q80_values[j]])\n",
    "            point_IQR = point_Q3 - point_Q1\n",
    "\n",
    "            upper_thresh = point_Q3 + 1.5 * point_IQR\n",
    "            lower_thresh = point_Q1 - 1.5 * point_IQR\n",
    "\n",
    "            if current_actual > upper_thresh or current_actual < lower_thresh:\n",
    "                score = (current_actual - upper_thresh\n",
    "                            ) / point_IQR if current_actual > upper_thresh else (\n",
    "                                lower_thresh - current_actual) / point_IQR\n",
    "\n",
    "                anomaly_timestamp_seconds = (window_start_ts.micros / 1e6) + (\n",
    "                    self._context_len + j)\n",
    "\n",
    "                index_in_window = self._context_len + j\n",
    "\n",
    "                anomalies_found.append({\n",
    "                    'key': key,\n",
    "                    'timestamp': Timestamp(anomaly_timestamp_seconds),\n",
    "                    'index_in_window': index_in_window,\n",
    "                    'actual_value': current_actual,\n",
    "                    'predicted_value': current_predicted_horizon_values[j],\n",
    "                    'is_anomaly': True,\n",
    "                    'outlier_score': score,\n",
    "                    'lower_bound': lower_thresh,\n",
    "                    'upper_bound': upper_thresh,\n",
    "                })\n",
    "        payload = {\n",
    "            \"start_ts_micros\": window_start_ts.micros,\n",
    "            \"predicted_values\": current_predicted_horizon_values.tolist(),\n",
    "            \"q20_values\": current_q20_values.tolist(),\n",
    "            \"q30_values\": current_q30_values.tolist(),\n",
    "            \"q70_values\": current_q70_values.tolist(),\n",
    "            \"q80_values\": current_q80_values.tolist(),\n",
    "            \"anomalies\": anomalies_found,  # Your original list is now inside the dictionary\n",
    "            \"actual_horizon_values\": actual_horizon_values.tolist()\n",
    "        }\n",
    "        result_with_context = (batch[0], payload)\n",
    "\n",
    "        return [result_with_context]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f21fa2-ea19-4dbc-a1ad-082a2ae0958d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 â€¢ TimesFM",
   "language": "python",
   "name": "tfm311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
